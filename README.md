# 求解Lasso回归算法分析


## 一、引言

Lasso（Least Absolute Shrinkage and Selection Operator）回归通过在损失函数中引入L1正则化项，能够实现特征选择和模型稀疏化，广泛应用于高维数据建模。本实验采用标准Lasso目标函数，数学形式为：
$$\min_{\beta} \frac{1}{2n}\|X\beta - y\|_2^2 + \lambda\|\beta\|_1 \tag{1}
$$
其中：$X \in \mathbb{R}^{n \times p}$为特征矩阵（$n$为样本数，$p$为特征数），$y \in \mathbb{R}^n$为标签向量，$\lambda>0$为正则化参数（控制稀疏化程度），$\beta \in \mathbb{R}^p$为待估计的系数向量，$\frac{1}{2n}$为残差平方和的归一化因子。

由于L1正则化项的非光滑性，传统梯度下降法难以直接应用，本文旨在通过实验比较5类主流Lasso求解算法的性能，重点分析不同（n,p）组合对算法计算效率和求解精度的影响，为算法选择提供参考。

## 二、实验设置

### 1. 测试算法

本次实验实现5类11种算法，具体实现细节如下：

1. **最速坐标下降法**（Coordinate Desc）
2. **临近点梯度法**（Proximal Gradient，ISTA）
3. **标准FISTA**、**带重启的FISTA**（FISTA (Restart)）
4. **ADMM**（$\rho=0.5,1,2,5$）
5. **Huber梯度法**、**加速Huber梯度法**、**带重启的加速Huber梯度法**

所有算法的迭代终止条件均为：达到最大迭代次数，未设置基于精度的终止条件，确保所有算法在相同迭代步数下进行公平比较。

### 2. 数据生成

- **真实系数向量$\beta_{\text{true}}$**：稀疏度为$10\%$（即$p \times 0.1$个非零元素），非零元素服从标准正态分布$\mathcal{N}(0,1)$
- **特征矩阵$X$**：每个元素独立服从标准正态分布$\mathcal{N}(0,1)$，生成后对每列进行标准化处理
- **标签向量$y$**：$y = X\beta_{\text{true}} + \epsilon$，其中噪声项$\epsilon \sim \mathcal{N}(0,0.1^2)$
- **数据标准化**：特征矩阵$X$和标签向量$y$均进行标准化处理，确保数值稳定性

### 3. 实验参数

- **独立重复实验次数**：$n_{\text{trials}}=100$（每次实验重新生成数据）
- **最大迭代次数**：$\text{max}_{iter}=75$（所有算法统一设置）
- **正则化参数**：$\lambda=0.1$（控制L1正则化强度）
- **Huber平滑参数**：$\mu=0.01$（用于Huber类算法平滑L1正则项）
- **ADMM惩罚参数**：$\rho \in \{0.5,1,2,5\}$（测试不同惩罚强度对ADMM性能的影响）
- **最优解参考**：使用scikit-learn库的Lasso实现（max_iter=10000，$\text{tol}=1e-8$）计算最优目标值$f^*$，作为次优性计算的基准

本次实验选取三种典型的维度组合，分别代表不同应用场景：

1. **低维场景**：n=200，p=50（$p<n$，特征数远小于样本数，传统统计学习场景）
2. **中维场景**：n=1000，p=200（$p<n$，样本数和特征数均较大，常规机器学习场景）
3. **高维场景**：n=500，p=1000（$p>n$，特征数大于样本数，高维小样本场景，Lasso的典型应用场景）

### 4. 评价指标

采用两个核心评价指标：

1. **最终次优性**：$f(\beta_k) - f^*$，其中$f(\beta)$为式(1)定义的目标函数值，$\text{max}_{iter}=75$，反映算法在最大迭代步数下的求解精度
2. **计算时间**：单次实验的总运行时间（单位：秒），反映算法的计算效率

## 三、算法原理与实现差异

### 1. 算法收敛理论

- **坐标下降法 (Coordinate Descent)**：每次迭代沿坐标轴方向搜索，在低维问题中计算简单，但高维时收敛慢，理论收敛速度为$O(1/k)$
- **临近点梯度法 (Proximal Gradient/ISTA)**：结合梯度下降与临近算子，收敛速度为$O(1/k)$，适合光滑+非光滑组合优化
- **FISTA系列**：采用Nesterov加速技术，收敛速度提升至$O(1/k^2)$，是ISTA的加速版本
- **ADMM系列**：将原始问题分解为多个子问题交替求解，适合可分离问题，收敛速度依赖于惩罚参数$\rho$的选择
- **Huber梯度法**：使用Huber函数平滑L1正则项，使目标函数可微，但引入近似误差$\sim O(\mu)$，其中$\mu$为平滑参数

### 2. 计算复杂度分析

在Lasso问题中，各算法单次迭代的计算复杂度如下：

- **梯度类算法**（ISTA、FISTA、Huber）：$O(np)$，主要开销为计算梯度$X^T(X\beta-y)$
- **坐标下降法**：$O(n)$（单坐标更新），但需要多次扫描所有坐标
- **ADMM**：$O(p^3)$（需要求解线性系统）或$O(np)$（利用预计算技巧）

从复杂度分析可初步解释：低维时坐标下降法高效，高维时梯度类算法更优，ADMM在$\rho$适当时可通过预计算加速。

## 四、实验结果与分析

### 1. 低维场景$(n=200, p=50)$

#### (1) 收敛性分析

![低维场景$(200,50)$的收敛云雾图](lasso_convergence_cloud_100_trials(200,50)[1].png)

图1为100次实验的收敛云雾图（阴影区域为单次实验的收敛轨迹，实线为100次实验的平均轨迹），收敛性分析如下：

- 除Huber类算法外，其余算法（坐标下降法、临近点梯度法、FISTA系列、ADMM系列）均能在75次迭代内收敛到最优解（次优性接近$1e-10$），表明这些算法在低维场景下对标准Lasso目标函数的求解有效性
- ADMM系列算法收敛速度最快，在10次迭代内即可达到最优解，且不同$\rho$值的ADMM性能差异较小
- FISTA系列和临近点梯度法收敛速度次之，约在20-30次迭代内收敛
- Huber类算法收敛后存在固定次优性误差（约$4.3e-3$），这是由于Huber函数对L1正则项的平滑近似导致的，平滑误差无法通过增加迭代次数消除
- 坐标下降法在低维场景下收敛速度最快，10次迭代内即可达到最优解，与其理论特性相符：当特征数$p$较小时，坐标轮询的效率很高

#### (2) 性能统计

![低维场景$(200,50)$算法性能比较（左：次优性箱线图；右：计算时间散点图）](lasso_performance_comparison_100_trials(200,50)[1].png)

**表1：低维场景$(200,50)$算法性能统计**

| 算法名称 | 平均最终次优性 | 次优性标准差 | 平均计算时间（秒） | 时间标准差 | 中位数时间（秒） |
|----------|----------------|--------------|-------------------|------------|------------------|
| Coordinate Desc | $0.000000$ | $0.000000$ | $0.001448$ | $0.000542$ | $0.001066$ |
| Proximal Gradient (ISTA) | $0.000000$ | $0.000000$ | $0.002973$ | $0.000509$ | $0.002988$ |
| FISTA | $0.000000$ | $0.000000$ | $0.003224$ | $0.000570$ | $0.002991$ |
| FISTA (Restart) | $0.000000$ | $0.000000$ | $0.003307$ | $0.000564$ | $0.002996$ |
| ADMM (rho=0.5) | $0.000000$ | $0.000000$ | $0.003356$ | $0.000567$ | $0.002996$ |
| ADMM (rho=1) | $0.000000$ | $0.000000$ | $0.003206$ | $0.000576$ | $0.002991$ |
| ADMM (rho=2) | $0.000000$ | $0.000000$ | $0.003280$ | $0.000624$ | $0.002994$ |
| ADMM (rho=5) | $0.000000$ | $0.000000$ | $0.003233$ | $0.000514$ | $0.002993$ |
| Huber Gradient | $0.004300$ | $0.000448$ | $0.005560$ | $0.000656$ | $0.005970$ |
| Accelerated Huber Gradient | $0.004271$ | $0.000439$ | $0.003304$ | $0.000532$ | $0.002994$ |
| Restarted Accelerated Huber Gradient | $0.004263$ | $0.000436$ | $0.004863$ | $0.000550$ | $0.004985$ |

根据代码运行结果和图1的箱线图和散点图分析可得：

**精度稳定性**：所有非Huber算法的次优性标准差为$0$，表明在100次随机试验中均能精确收敛；Huber算法的次优性标准差约$4.4\times10^{-4}$，相对稳定但存在系统性偏差。

**时间稳定性**：坐标下降法的时间标准差最大（$5.42\times10^{-4}$秒），这与每次实验中选择的初始坐标顺序和活跃集变化有关；其他算法时间标准差相近（$5.0\times10^{-4}$-$6.6\times10^{-4}$秒），表现稳定。

**表2：低维场景下不同优化算法的性能对比结论**

| 评估指标 | 算法类别/名称 | 关键结论 |
|----------|--------------|----------|
| **求解精度** | 坐标下降法、临近点梯度法、FISTA系列、ADMM系列 | 均能达到最优解，平均次优性为$0$，与收敛性分析一致 |
| | Huber类算法（标准/带重启加速） | 存在固定次优性误差；带重启的加速Huber梯度法误差最小（$4.263e-3$），标准Huber梯度法误差最大（$4.300e-3$），表明加速和重启策略对精度有轻微提升 |
| **计算速度** | 坐标下降法 | 速度最快，平均时间$0.001448$秒，是所有算法中计算效率最高的 |
| | ADMM系列、临近点梯度法、FISTA系列、加速Huber梯度法 | 速度相近，属于中等速度算法，平均时间$0.0032$-$0.0034$秒 |
| | 标准Huber梯度法、带重启的加速Huber梯度法 | 速度较慢，平均时间分别为$0.005560$秒和$0.004863$秒 |

### 2. 中维场景$(n=1000, p=200)$

#### (1) 收敛性分析

![中维场景$(1000,200)$的收敛云雾图](lasso_convergence_cloud_100_trials(1000,200)[1].png)

图2为中维场景的收敛云雾图。与低维场景相比，中维场景下样本数和特征数均增加，算法收敛性呈现以下特点：

- ADMM系列算法和FISTA系列算法收敛速度最快，在15次迭代内达到最优解
- 坐标下降法收敛速度次之，约在20次迭代内达到最优解
- 临近点梯度法收敛速度略慢，需30次迭代达到最优解
- Huber类算法的次优性误差约为$1.47e-2$，比低维场景更大，说明平滑误差随维度增加而增大

#### (2) 性能统计

![中维场景$(1000,200)$算法性能比较（左：次优性箱线图；右：计算时间散点图）](lasso_performance_comparison_100_trials(1000,200)[1].png)

**表3：中维场景$(1000,200)$算法性能统计**

| 算法名称 | 平均最终次优性 | 次优性标准差 | 平均计算时间（秒） | 时间标准差 | 中位数时间（秒） |
|----------|----------------|--------------|-------------------|------------|------------------|
| Coordinate Desc | $0.000000$ | $0.000000$ | $0.018719$ | $0.003926$ | $0.018228$ |
| Proximal Gradient (ISTA) | $0.000000$ | $0.000000$ | $0.022259$ | $0.005160$ | $0.021747$ |
| FISTA | $0.000000$ | $0.000000$ | $0.019076$ | $0.006368$ | $0.017942$ |
| FISTA (Restart) | $0.000000$ | $0.000000$ | $0.018492$ | $0.003385$ | $0.017940$ |
| ADMM (rho=0.5) | $0.000000$ | $0.000000$ | $0.019628$ | $0.004693$ | $0.018934$ |
| ADMM (rho=1) | $0.000000$ | $0.000000$ | $0.019548$ | $0.004229$ | $0.018936$ |
| ADMM (rho=2) | $0.000000$ | $0.000000$ | $0.019661$ | $0.004326$ | $0.018938$ |
| ADMM (rho=5) | $0.000000$ | $0.000000$ | $0.019309$ | $0.004035$ | $0.018936$ |
| Huber Gradient | $0.014771$ | $0.000746$ | $0.063831$ | $0.011316$ | $0.061381$ |
| Accelerated Huber Gradient | $0.014741$ | $0.000744$ | $0.022845$ | $0.010000$ | $0.018959$ |
| Restarted Accelerated Huber Gradient | $0.014732$ | $0.000744$ | $0.023030$ | $0.005674$ | $0.021927$ |

**表4：中维场景下不同优化算法的性能对比结论**

| 评估指标 | 算法类别/名称 | 关键结论 |
|----------|--------------|----------|
| **求解精度** | 除Huber类算法外的其余算法 | 仍能达到最优解（平均次优性为$0$），表明中维场景下对标准Lasso目标函数的求解精度不受维度增加影响 |
| | Huber类算法 | 平均次优性为$1.47e-2$，较低维场景增加约$3.4$倍，表明平滑误差随维度增加而显著增大 |
| **计算速度** | FISTA (Restart) | 速度最快，平均时间$0.018492$秒 |
| | 坐标下降法、FISTA、ADMM系列 | 速度相近，平均时间$0.0187$-$0.0197$秒 |
| | 临近点梯度法、加速Huber梯度法、带重启的加速Huber梯度法 | 平均时间$0.022$-$0.023$秒，较慢 |
| | 标准Huber梯度法 | 速度最慢，平均时间$0.063831$秒，是其他算法的3-4倍 |

### 3. 高维场景$(n=500, p=1000)$

#### (1) 收敛性分析

![高维场景$(500,1000)$的收敛云雾图](lasso_convergence_cloud_100_trials(500,1000)[1].png)

图3为高维场景（$p > n$）的收敛云雾图。高维场景下特征数远超样本数，是Lasso的典型应用场景。值得注意的是，FISTA系列算法在此场景下展现出最强的适应性，收敛性呈现以下显著变化：

- FISTA系列算法收敛速度最快，在10次迭代内达到最优解
- ADMM系列算法（除$\rho=0.5$外）收敛速度次之，在20次迭代内达到最优解
- 坐标下降法和临近点梯度法收敛速度较慢，需40-50次迭代才能接近最优解
- Huber类算法的次优性误差进一步增大至$0.130$左右，比中维场景增加约$8.8$倍，表明高维场景下Huber平滑近似效果显著变差
- ADMM ($\rho=0.5$)存在微小误差（$1.24e-4$），说明惩罚参数选择对ADMM精度有影响

#### (2) 性能统计

![高维场景$(500,1000)$算法性能比较（左：次优性箱线图；右：计算时间散点图）](figures/lasso_performance_comparison_100_trials(500,1000).png)

**表5：高维场景$(500,1000)$算法性能统计**

| 算法名称 | 平均最终次优性 | 次优性标准差 | 平均计算时间（秒） | 时间标准差 | 中位数时间（秒） |
|----------|----------------|--------------|-------------------|------------|------------------|
| Coordinate Desc | $0.000000$ | $0.000000$ | $0.147100$ | $0.021645$ | $0.144175$ |
| Proximal Gradient (ISTA) | $0.000000$ | $0.000000$ | $0.137919$ | $0.015891$ | $0.135692$ |
| FISTA | $0.000000$ | $0.000000$ | $0.128444$ | $0.014938$ | $0.127967$ |
| FISTA (Restart) | $0.000000$ | $0.000000$ | $0.128370$ | $0.013387$ | $0.128355$ |
| ADMM (rho=0.5) | $0.000124$ | $0.000021$ | $0.189256$ | $0.023812$ | $0.182965$ |
| ADMM (rho=1) | $0.000000$ | $0.000000$ | $0.190712$ | $0.024314$ | $0.192886$ |
| ADMM (rho=2) | $0.000000$ | $0.000000$ | $0.193852$ | $0.027317$ | $0.192224$ |
| ADMM (rho=5) | $0.000001$ | $0.000000$ | $0.196877$ | $0.029808$ | $0.198829$ |
| Huber Gradient | $0.130926$ | $0.002646$ | $0.245529$ | $0.047040$ | $0.239792$ |
| Accelerated Huber Gradient | $0.130514$ | $0.002653$ | $0.136894$ | $0.015766$ | $0.136146$ |
| Restarted Accelerated Huber Gradient | $0.130482$ | $0.002660$ | $0.134269$ | $0.016133$ | $0.133097$ |

**表6：高维场景下不同优化算法的性能对比结论**

| 评估指标 | 算法类别/名称 | 关键结论 |
|----------|--------------|----------|
| **求解精度** | FISTA系列、坐标下降法、临近点梯度法、ADMM（$\rho=1,2$） | 仍能达到最优解（平均次优性为$0$），表现出良好的高维求解能力 |
| | ADMM（$\rho=0.5$） | 平均次优性为$1.24e-4$，略高于其他ADMM变体，表明$\rho$选择对高维场景下的ADMM精度有轻微影响 |
| | ADMM（$\rho=5$） | 平均次优性为$1e-6$，几乎达到最优解 |
| | Huber类算法 | 平均次优性大幅增加至$0.130$左右，是低维场景的$30$倍，高维场景下Huber平滑近似效果显著变差 |
| **计算速度** | FISTA系列算法 | 速度最快，平均时间$0.128$-$0.1284$秒 |
| | 坐标下降法、临近点梯度法、加速Huber梯度法 | 平均时间$0.1369$-$0.1471$秒，属于中等速度 |
| | ADMM系列算法 | 平均时间$0.189$-$0.197$秒，较慢 |
| | 标准Huber梯度法 | 速度最慢，平均时间$0.245529$秒，比FISTA慢约91% |

### 4. 跨场景综合对比

为更直观地比较各算法在不同维度场景下的性能变化，下表汇总了各算法在三种场景下的平均计算时间和精度等级（最优解：A；微小误差：B；固定误差：C）。

**表7：跨场景算法性能综合对比**

| 算法名称 | 低维$(200,50)$ | 中维$(1000,200)$ | 高维$(500,1000)$ | 精度等级 | 速度排名（高维） | 综合排名 |
|----------|----------------|------------------|------------------|----------|------------------|----------|
| FISTA (Restart) | $0.003307$秒 / $0$ | $0.018492$秒 / $0$ | $0.128370$秒 / $0$ | A | 1 | 1 |
| FISTA | $0.003224$秒 / $0$ | $0.019076$秒 / $0$ | $0.128444$秒 / $0$ | A | 2 | 2 |
| Coordinate Desc | $0.001448$秒 / $0$ | $0.018719$秒 / $0$ | $0.147100$秒 / $0$ | A | 3 | 3 |
| ADMM (rho=1) | $0.003206$秒 / $0$ | $0.019548$秒 / $0$ | $0.190712$秒 / $0$ | A | 6 | 4 |
| ADMM (rho=2) | $0.003280$秒 / $0$ | $0.019661$秒 / $0$ | $0.193852$秒 / $0$ | A | 7 | 5 |
| ADMM (rho=5) | $0.003233$秒 / $0$ | $0.019309$秒 / $0$ | $0.196877$秒 / $1e-6$ | A | 8 | 6 |
| Proximal Gradient (ISTA) | $0.002973$秒 / $0$ | $0.022259$秒 / $0$ | $0.137919$秒 / $0$ | A | 4 | 7 |
| Restarted Accelerated Huber Gradient | $0.004863$秒 / $4.263e-3$ | $0.023030$秒 / $1.473e-2$ | $0.134269$秒 / $0.130482$ | C | 5 | 8 |
| Accelerated Huber Gradient | $0.003304$秒 / $4.271e-3$ | $0.022845$秒 / $1.474e-2$ | $0.136894$秒 / $0.130514$ | C | 9 | 9 |
| ADMM (rho=0.5) | $0.003356$秒 / $0$ | $0.019628$秒 / $0$ | $0.189256$秒 / $1.24e-4$ | A/B | 10 | 10 |
| Huber Gradient | $0.005560$秒 / $4.300e-3$ | $0.063831$秒 / $1.477e-2$ | $0.245529$秒 / $0.130926$ | C | 11 | 11 |

**注**：表格中数值格式为「计算时间 / 最终次优性」；精度等级A：达到最优解；B：微小误差（$<1e-4$）；C：显著误差（$>1e-2$）；所有指标基于标准Lasso目标函数式(1)

#### (1) 算法性能排名（综合精度和速度）

1. **第一梯队：FISTA系列**
   - **精度**：所有场景下均达到最优解（等级$\mathbf{A}$）
   - **速度**：低维场景中等，中高维场景最快或接近最快
   - **适应性**：对低维、中维、高维场景均表现优异，尤其是高维场景下性能最优

2. **第二梯队：坐标下降法**
   - **精度**：所有场景下均达到最优解（等级$\mathbf{A}$）
   - **速度**：低维场景最快，中维场景中等，高维场景较慢
   - **适应性**：特别适合低维场景，高维场景下效率下降明显

3. **第三梯队：ADMM系列（除$\rho=0.5$外）**
   - **精度**：所有场景下均达到最优解（等级$\mathbf{A}$）
   - **速度**：低维场景中等，中维场景中等，高维场景较慢
   - **适应性**：各类场景下表现稳定，但高维场景下速度不如FISTA系列

4. **第四梯队：临近点梯度法**
   - **精度**：所有场景下达到最优解（等级$\mathbf{A}$）
   - **速度**：低维场景中等，中维场景较慢，高维场景中等
   - **适应性**：适合低维和中维场景，高维场景下性能一般

5. **第五梯队：加速Huber类算法**
   - **精度**：存在显著次优性误差（等级$\mathbf{C}$），且误差随维度增加而急剧增大
   - **速度**：低维场景中等，中维场景较慢，高维场景中等
   - **适应性**：仅在对精度要求极低的特殊场景下考虑

6. **第六梯队：标准Huber梯度法**
   - **精度**：存在显著次优性误差（等级$\mathbf{C}$）
   - **速度**：所有场景下均最慢
   - **适应性**：不推荐使用

#### (2) 维度变化对算法的影响

- **对FISTA系列**：在所有维度场景下均表现优异，受影响最小
- **对坐标下降法**：时间随维度增长显著增加，低维场景优势明显，高维场景效率下降
- **对ADMM系列**：时间随维度增长增加，精度保持稳定（除$\rho=0.5$外）
- **对临近点梯度法**：时间随维度增长增加，但幅度相对平缓
- **对Huber类算法**：精度随维度增加急剧恶化，时间增长相对平缓
- **对标准Huber梯度法**：影响最大，时间和精度均表现最差

## 五、算法鲁棒性与稳定性分析

### 1. 次优性稳定性分析

通过比较各算法次优性的标准差（Std Final Suboptimality），可以评估算法的稳定性：

- **高稳定性算法**：所有ADMM变体（标准差$<1e-5$）、FISTA系列（标准差$=0$），在100次随机试验中表现一致
- **中等稳定性算法**：坐标下降法、临近点梯度法（标准差接近0）
- **低稳定性算法**：Huber类算法（标准差$2.6e-4$-$2.7e-4$），虽然绝对误差大，但相对稳定性尚可

高稳定性表明算法对初始值和数据随机性不敏感，适合实际应用。

### 2. 计算时间稳定性分析

从时间标准差看：

- **最稳定**：ADMM ($\rho$=1) 在所有场景下时间标准差最小，运行时间可预测性强
- **较稳定**：FISTA (Restart)、坐标下降法
- **最不稳定**：标准Huber梯度法（高维时时间标准差达$0.047$秒），可能与收敛过程振荡有关

### 3. 算法对参数敏感度

- **ADMM对$\rho$敏感度**：实验显示$\rho$=0.5时在高维场景出现微小误差($1.24e-4$)，而$\rho$=1,2,5时精度无损，建议$\rho≥1$
- **Huber对$\mu$敏感度**：固定$\mu=0.01$时，误差随维度线性增长，高维场景需调整$\mu$值
- **FISTA重启策略**：带重启的FISTA在低维稍慢但高维略快，重启策略对性能影响有限

### 4. 理论收敛速度与实际计算时间的差异

实验观察与理论分析的差异可由以下因素解释：

**表8：理论收敛速度与实际表现对比**

| 算法 | 理论收敛率 | 实际表现 | 差异原因 |
|------|------------|----------|----------|
| 坐标下降法 | 线性收敛（对Lasso） | 低维最优，高维中等 | 实际常数小，但每迭代成本高 |
| FISTA | $O(1/k^2)$ | 高维最优 | 理论优势在高维显现 |
| ADMM | 线性收敛 | 稳定但非最快 | 每迭代需解线性系统 |
| Huber梯度法 | $O(1/k)$（光滑问题） | 精度差 | L1近似引入固定误差 |

**关键见解**：
- **坐标下降法**的理论收敛常数小，但每迭代需更新所有坐标，导致总时间增长快
- **FISTA**的理论优势在迭代次数多时（高维问题需要更多迭代）才明显
- **算法常数因子**在实际中比渐近阶数更重要，尤其在问题规模适中时

## 六、结论与建议

### 1. 实验结论

通过对三种维度场景的100次独立实验，得出以下结论：

- **FISTA系列算法**（尤其是带重启的FISTA）在所有维度场景下均表现最优，兼顾求解精度（达到最优解）和计算效率（最快或接近最快），且对维度变化的适应性最强，是标准Lasso回归的首选算法
- **坐标下降法**在低维场景下效率最高，能达到最优解，但在高维场景下计算时间显著增加
- **ADMM系列算法**（$\rho=1,2,5$）在所有场景下均能达到最优解，但计算速度在中高维场景下不如FISTA系列
- **临近点梯度法**在所有场景下能达到最优解，但计算效率一般
- **Huber类算法**求解速度中等，但存在显著次优性误差，且误差随维度增加急剧增大，不适合精度要求较高的场景
- **标准Huber梯度法**在所有场景下均表现最差，不推荐使用
- **维度变化对不同算法的影响差异显著**：FISTA系列受影响最小，坐标下降法在速度上受维度影响最大，Huber类算法在精度上受维度影响最大

### 2. 应用建议

- **高维小样本场景（$p>n$）**：优先选择FISTA系列（尤其是带重启的FISTA），兼顾精度和速度；坐标下降法可作为备选，但效率较低
- **中维场景（$p<n$且样本数较大）**：FISTA系列仍为最优选择；坐标下降法和ADMM系列也是良好选择
- **低维场景（$p<n$且样本数较小）**：坐标下降法效率最高，FISTA系列和ADMM系列也是良好选择
- **算法参数选择**：ADMM的惩罚参数$\rho$建议选择$1\sim5$，避免使用$\rho=0.5$；Huber平滑参数$\mu$需要根据维度调整，高维场景下可能需要更小的$\mu$值

